# -*- coding: utf-8 -*-
# =====================================================================================
# Car Advisor â€“ Batch A/B Harness (Tool vs Chat)
# 50 ×©××œ×•× ×™× ×××™×ª×™×™× (×¡×™××•×œ×¦×™×”), Gemini (×¤×¨×•××¤×˜ ××§×¦×•×¢×™) ××•×œ ChatGPT (×¤×¨×•×¤×™×œ ×‘×œ×‘×“)
# ×¤×œ×˜: ×˜×‘×œ×” ××œ××” + ×¦×™×•×Ÿ ×œ×›×œ ××•×“×œ + ×× ×¦×— ×œ×›×œ ×©××œ×•×Ÿ, ×©××™×¨×” ×œ-JSON ×•×™×¦×•× CSV
# =====================================================================================

import streamlit as st
import os, json, time, random, traceback
from datetime import datetime
from typing import List, Dict, Any, Optional
import pandas as pd

# --- APIs ---
import google.generativeai as genai
from json_repair import repair_json
try:
    from openai import OpenAI
except Exception:
    OpenAI = None

st.set_page_config(page_title="Car Advisor â€“ A/B Reliability Harness", page_icon="ğŸš—", layout="wide")

# ==========================
# CONFIG & SECRETS
# ==========================
GEMINI_MODEL = "gemini-2.5-flash"
OPENAI_MODEL = "gpt-4o-mini"   # ×¢×“×›×Ÿ ×× ×ª×¨×¦×”
RUN_DIR = "runs"
os.makedirs(RUN_DIR, exist_ok=True)
RUN_ROWS_FILE = os.path.join(RUN_DIR, "batch_rows.json")
RUN_SUMMARY_FILE = os.path.join(RUN_DIR, "batch_summary.json")

GEMINI_API_KEY = st.secrets.get("GEMINI_API_KEY", "")
OPENAI_API_KEY = st.secrets.get("OPENAI_API_KEY", "")

if not GEMINI_API_KEY:
    st.warning("âš ï¸ ×—×¡×¨ GEMINI_API_KEY ×‘-secrets.")
if not OPENAI_API_KEY:
    st.warning("âš ï¸ ×—×¡×¨ OPENAI_API_KEY ×‘-secrets.")

genai.configure(api_key=GEMINI_API_KEY)
gemini_client = genai.GenerativeModel(GEMINI_MODEL)
oa_client = OpenAI(api_key=OPENAI_API_KEY) if (OPENAI_API_KEY and OpenAI) else None

# ==========================
# PROMPTS
# ==========================
# ×–×”×” ×œ×¢×§×¨×•× ×•×ª ×”××§×¦×•×¢×™×™× ×‘×§×•×“ ×©×œ×š: ×”×—×–×¨ JSON ××œ× ×‘×œ×‘×“
GEMINI_SYSTEM_PROMPT = """××ª×” ×× ×œ×™×¡×˜ ××•××—×” ×œ×©×•×§ ×”×¨×›×‘ ×”×™×©×¨××œ×™. ×§×‘×œ ×¤×¨×•×¤×™×œ ×©××œ×•×Ÿ ×©×œ ××©×ª××©, × ×ª×— ×œ×¤×™ ×©×œ×‘×™×, ×™×™×©× 18 ××§×¨×™ ×§×¦×”, ×•×”×—×–×¨ JSON ×‘×œ×‘×“ ×‘×¤×•×¨××˜ ×©× ×“×¨×©. ××œ ×ª×—×–×™×¨ ×˜×§×¡×˜ ××—×•×¥ ×œ-JSON."""
GEMINI_LONG_RULES = """
--- ×©×œ×‘×™ × ×™×ª×•×— (××§×•×¦×¨ ×œ× ×™×¡×•×™, ×ª×•×× ×¢×§×¨×•× ×•×ª ×”×›×œ×™) ---
1) ×¤×¢× ×•×— ×¤×¨×˜×™ ×”×¦×•×¨×š ××ª×•×š ×”×¤×¨×•×¤×™×œ (×ª×§×¦×™×‘, ×©×™××•×©, ×“×¨×™×©×•×ª, ××™×œ×•×¦×™×).
2) × ×™×ª×•×— ×©×•×§/×§×˜×’×•×¨×™×”/××ª×—×¨×™× ×•×”××œ×¦×” ××•×ª×××ª.
3) 18 ××§×¨×™ ×§×¦×” (×›×¤×™ ×©××¤×•×¨×˜ ×‘×§×•×“ ×”××§×•×¨×™ ×©×œ×š) â€“ ×™×© ×œ×™×™×©×.
4) ×¡×›× ×‘-short_verdict ×‘×¢×‘×¨×™×ª ×¨×”×•×˜×”.

--- × ×•×¡×—×ª ×¦×™×•×Ÿ (0â€“100) ---
××—×™×¨ ××•×œ ×©×•×§ 25% â€¢ ×ª×—×–×•×§×”/××¦×‘ 25% â€¢ ×××™× ×•×ª ×“×’× 20% â€¢ ×’×™×œ/×§×´× 15% â€¢ ×××™× ×•×ª ××•×›×¨ 10% â€¢ ×‘×™×§×•×© 5%

×”×—×–×¨ JSON ×‘×œ×‘×“:
{
  "from_ad": {"brand":"", "model":"", "year":0, "mileage_km":0, "price_nis":0},
  "deal_score": 0,
  "classification": "",
  "short_verdict": "",
  "key_reasons": [],
  "user_info": {"reliability_summary":"", "maintenance_tips":[], "common_faults":[], "market_context":""},
  "recommendations": [{"car":"", "why":""}]
}
"""

# ChatGPT â€“ ××©×ª××© ×¨×’×™×œ: ××§×‘×œ ×¨×§ ×”×¤×¨×•×¤×™×œ + ××©×¤×˜ ×‘×§×©×”. ×‘×œ×™ ×›×‘×œ×™×/×¡×›××”. ×œ× ×ª× ××™ ××¢×‘×“×”.
USER_ONE_LINER = "×ª××œ×™×¥ ×œ×™ 5 ×¨×›×‘×™× ×¢×œ ×¤×™ ×”×¦×¨×›×™× ×©×¦×•×™× ×• ×‘×¤×¨×•×¤×™×œ."

# Evaluator â€“ × ×•×ª×Ÿ ×¦×™×•×Ÿ ×œ×›×œ ××•×“×œ ×•×‘×•×—×¨ ×× ×¦×— ×¢× × ×™××•×§
EVAL_PROMPT = """
×× × ×“×¨×’ ×©×ª×™ ×ª×©×•×‘×•×ª (Gemini JSON ×•-GPT Raw/JSON) ×¢×‘×•×¨ ××•×ª×• ×¤×¨×•×¤×™×œ.
×§×¨×™×˜×¨×™×•× ×™×: ×¨×œ×•×•× ×˜×™×•×ª ×œ×¦×¨×›×™×, ×¢×•××§ ×•×”×™×’×™×•×Ÿ ××§×¦×•×¢×™, ×¢×§×‘×™×•×ª, ×‘×”×™×¨×•×ª, ×ª×•×¢×œ×ª ××¢×©×™×ª.
×”×—×–×¨ JSON ×‘×œ×‘×“:
{
  "gemini_score": 0,   // 0-100
  "gpt_score": 0,      // 0-100
  "winner": "Gemini" | "ChatGPT" | "Tie",
  "reason": "× ×™××•×§ ×§×¦×¨ ×‘×¢×‘×¨×™×ª"
}
"""

# ==========================
# DATA: 50 QUESTIONNAIRES
# ==========================
# "×‘×•×œ ×›××• ×©×”××©×ª××© ×××œ×": ×¤×¨×•×¤×™×œ ××œ×, ×œ×œ× ××•×“×¢×” â€“ ×©×™××•×©×™×/×¢×“×™×¤×•×™×•×ª/××™×œ×•×¦×™×.
# ××’×•×•×Ÿ ×¨×—×‘ ×¢"×™ ×¨× ×“×•× ×“×˜×¨××™× ×™×¡×˜×™ (seed), ××‘×œ ×”×¤×•×¨××˜ ×§×‘×•×¢ ×•×‘×¨×•×¨.
def build_questionnaire(i: int) -> Dict[str, Any]:
    random.seed(1000 + i)
    budget = random.choice([45000, 60000, 75000, 90000, 110000, 130000, 160000, 200000])
    age = random.choice([22, 27, 31, 36, 42, 48])
    annual_km = random.choice([8000, 12000, 15000, 20000, 30000])
    family = random.choice([1, 2, 3, 4, 5])
    primary_use = random.choice([
        "× ×¡×™×¢×•×ª ×™×•××™×•××™×•×ª ×‘×¢×™×¨", "× ×¡×™×¢×•×ª ×‘×™×Ÿ-×¢×™×¨×•× ×™×•×ª ××¨×•×›×•×ª", "×”×©×›×¨×” ×§×œ×” ×œ××©×¤×—×”",
        "×˜×™×•×œ×™× ×‘×¡×•×¤×™ ×©×‘×•×¢", "× ×¡×™×¢×•×ª ×¢×‘×•×“×” ×¢× ×¦×™×•×“"
    ])
    gearbox = random.choice(["××•×˜×•××˜", "×™×“× ×™", "DCT/DSG", "CVT"])
    engine = random.choice(["×‘× ×–×™×Ÿ", "×“×™×–×œ", "×”×™×‘×¨×™×“×™", "×¤×œ××’-××™×Ÿ", "×—×©××œ×™"])
    body = random.choice(["×”××¦'×‘×§", "×¡×“××Ÿ", "×§×¨×•×¡××•×‘×¨", "×¡×˜×™×™×©×Ÿ", "××™× ×™"])
    pri = random.choice(["×××™× ×•×ª", "×—×™×¡×›×•×Ÿ ×‘×“×œ×§", "× ×•×—×•×ª", "×‘×™×¦×•×¢×™×", "×©××™×¨×ª ×¢×¨×š", "×‘×˜×™×—×•×ª"])
    secondary = random.sample(["×××™× ×•×ª", "×—×™×¡×›×•×Ÿ ×‘×“×œ×§", "× ×•×—×•×ª", "×‘×™×¦×•×¢×™×", "×©××™×¨×ª ×¢×¨×š", "×‘×˜×™×—×•×ª"], k=2)
    musts = random.sample(["×‘×§×¨×ª ×©×™×•×˜ ××“×¤×˜×™×‘×™×ª", "×‘×œ×™××” ××•×˜×•× ×•××™×ª", "××¡×š ×’×“×•×œ", "×ª× ××˜×¢×Ÿ ×’×“×•×œ", "×—×™×™×©× ×™ ×—× ×™×”", "××•×©×‘ × ×”×’ ×—×©××œ×™", "××¢×¨×›×ª ×‘×˜×™×—×•×ª ××ª×§×“××ª"], k=3)
    nice = random.sample(["Sunroof", "××¢×¨×›×ª ×©××¢ ×¤×¨×™××™×•×", "×˜×¢×™× ×ª ××œ×—×•×˜", "×¢×•×¨", "×’'×× ×˜×™×"], k=2)
    parking = random.choice(["×¢×™×¨ ×¦×¤×•×¤×”", "×¤×¨×‘×¨", "×›×¤×¨×™"])
    region = random.choice(["××¨×›×–", "×©×¤×œ×”", "×¦×¤×•×Ÿ", "×“×¨×•×", "×™×¨×•×©×œ×™×", "×—×•×£"])
    risk = random.choice(["× ××•×›×”", "×‘×™× ×•× ×™×ª", "×’×‘×•×”×”"])

    return {
        "profile_id": f"Q{i:02d}",
        "budget_nis": budget,
        "driver_age": age,
        "annual_km": annual_km,
        "family_size": family,
        "primary_use": primary_use,
        "preferences": {
            "gearbox": gearbox,
            "engine_type": engine,
            "body_style": body,
            "priority_primary": pri,
            "priority_secondary": secondary,
            "performance_importance": random.randint(1,5),
            "comfort_importance": random.randint(1,5),
            "reliability_importance": random.randint(1,5),
            "safety_importance": random.randint(1,5)
        },
        "must_haves": musts,
        "nice_to_have": nice,
        "parking": parking,
        "region": region,
        "risk_tolerance": risk,
        "notes": random.choice([
            "× ×¡×™×¢×•×ª ×™×•××™×•××™×•×ª + ×©× ×™ ×™×œ×“×™× ×§×˜× ×™×", "× ×”×™×’×” ×‘×™×Ÿ-×¢×™×¨×•× ×™×ª 60% ××”×–××Ÿ",
            "×¨×›×‘ ×§×•×“× ×”×™×” ×™×§×¨ ×‘×ª×—×–×•×§×”", "×—× ×™×” ×¦×¤×•×¤×” ×œ×™×“ ×”×‘×™×ª", "×¨×•×¦×” ×¨×›×‘ ×©×•××¨ ×¢×¨×š"
        ])
    }

QUESTIONNAIRES: List[Dict[str, Any]] = [build_questionnaire(i+1) for i in range(50)]

# ==========================
# UTILS
# ==========================
def safe_parse_json(text: Optional[str]) -> Dict[str, Any]:
    if not text:
        return {}
    try:
        fixed = repair_json(text)
        return json.loads(fixed)
    except Exception:
        return {}

def load_list(path: str) -> List[Dict[str, Any]]:
    if os.path.exists(path):
        try:
            with open(path, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception:
            return []
    return []

def append_row(path: str, row: Dict[str, Any]):
    data = load_list(path)
    data.append(row)
    with open(path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

def call_with_retry(fn, retries=3, base_sleep=1.2):
    last_err = None
    for i in range(retries):
        try:
            return fn()
        except Exception as e:
            last_err = e
            time.sleep(base_sleep * (i+1))
    raise last_err

# ==========================
# MODEL CALLS
# ==========================
def run_gemini(profile: Dict[str, Any]) -> Dict[str, Any]:
    def _call():
        resp = gemini_client.generate_content(
            [GEMINI_SYSTEM_PROMPT, f"×¤×¨×•×¤×™×œ ×©××œ×•×Ÿ ××©×ª××© (JSON):\n{json.dumps(profile, ensure_ascii=False, indent=2)}\n{GEMINI_LONG_RULES}"],
            request_options={"timeout": 120}
        )
        return safe_parse_json(resp.text)
    try:
        return call_with_retry(_call, retries=3)
    except Exception:
        return {"_error": traceback.format_exc()}

def run_chat_gpt(profile: Dict[str, Any]) -> Dict[str, Any]:
    if oa_client is None:
        return {"_raw": "OpenAI client unavailable.", "_json": {}}
    def _call():
        resp = oa_client.chat.completions.create(
            model=OPENAI_MODEL,
            messages=[
                {"role": "user", "content": json.dumps(profile, ensure_ascii=False)},
                {"role": "user", "content": USER_ONE_LINER}
            ],
            temperature=0.6,   # ×™×•×ª×¨ "××©×ª××©", ×œ× ×ª× ××™ ××¢×‘×“×”
        )
        text = resp.choices[0].message.content
        parsed = safe_parse_json(text)  # ×× ×™×—×–×™×¨ JSON â€“ × ×§×œ×•×˜. ×× ×œ× â€“ × ×©××•×¨ raw ×‘×œ×‘×“.
        return {"_raw": text, "_json": parsed}
    try:
        return call_with_retry(_call, retries=3)
    except Exception:
        return {"_raw": traceback.format_exc(), "_json": {}}

def run_evaluator(profile: Dict[str, Any], gem_json: Dict[str, Any], gpt_pack: Dict[str, Any]) -> Dict[str, Any]:
    if oa_client is None:
        return {"gemini_score": 0, "gpt_score": 0, "winner": "Tie", "reason": "Evaluator unavailable."}
    def _call():
        payload = [
            {"role": "system", "content": "You are a strict evaluator. Hebrew output only, JSON only."},
            {"role": "user", "content": f"PROFILE:\n{json.dumps(profile, ensure_ascii=False, indent=2)}"},
            {"role": "user", "content": f"GEMINI_JSON:\n{json.dumps(gem_json, ensure_ascii=False, indent=2)}"},
            {"role": "user", "content": f"GPT_RAW:\n{gpt_pack.get('_raw','')}"},
            {"role": "user", "content": f"GPT_JSON:\n{json.dumps(gpt_pack.get('_json', {}), ensure_ascii=False, indent=2)}"},
            {"role": "user", "content": EVAL_PROMPT},
        ]
        resp = oa_client.chat.completions.create(
            model=OPENAI_MODEL,
            messages=payload,
            temperature=0.0
        )
        return safe_parse_json(resp.choices[0].message.content)
    try:
        return call_with_retry(_call, retries=2)
    except Exception:
        return {"gemini_score": 0, "gpt_score": 0, "winner": "Tie", "reason": "Evaluation failed."}

# ==========================
# UI
# ==========================
st.title("ğŸš— Car Advisor â€“ ××‘×—×Ÿ ××™××¤×§×˜: ×›×œ×™ ××§×¦×•×¢×™ (Gemini) ××•×œ ×¦'××˜ (ChatGPT)")
st.caption("50 ×©××œ×•× ×™× ×¨×™××œ×™×™× â€¢ Gemini ×¢× ×¤×¨×•××¤×˜ ××§×¦×•×¢×™ â€¢ GPT ×¨×§ ×¢× ×¤×¨×•×¤×™×œ â€¢ ×˜×‘×œ×ª ×¤×œ×˜ ××œ××” + ×¦×™×•× ×™ Evaluator")

with st.sidebar:
    st.markdown("### ×”×’×“×¨×•×ª")
    n = st.slider("××¡×¤×¨ ×©××œ×•× ×™× ×œ×”×¨×¦×”", 10, 50, 50, step=5)
    seed = st.number_input("Seed ×œ×¨× ×“×•× (×œ×¡×“×¨ ×”×”×¨×¦×” ×‘×œ×‘×“)", min_value=0, max_value=999999, value=42, step=1)
    run_btn = st.button("ğŸš€ ×”×ª×—×œ ×”×¨×¦×” ×¨×¦×™×¤×”")

# ×”×™×¡×˜×•×¨×™×” ×§×¦×¨×”
prev_rows = load_list(RUN_ROWS_FILE)
st.write(f"ğŸ“ ×¨×©×•××•×ª ×§×™×™××•×ª: {len(prev_rows)}")
if prev_rows:
    st.dataframe(pd.DataFrame([{
        "time": r.get("ts","")[:19].replace("T"," "),
        "qid": r.get("profile",{}).get("profile_id",""),
        "winner": r.get("eval",{}).get("winner",""),
        "gemini_score": r.get("eval",{}).get("gemini_score",""),
        "gpt_score": r.get("eval",{}).get("gpt_score",""),
    } for r in prev_rows][-100:]), use_container_width=True)

status_box = st.empty()
progress = st.progress(0)

# ×ª×¦×•×’×ª ×ª×•×¦××•×ª ×¨×™×¦×” ×–×•
run_rows: List[Dict[str, Any]] = []

if run_btn:
    random.seed(seed)
    chosen = QUESTIONNAIRES[:]
    random.shuffle(chosen)
    chosen = chosen[:n]

    for idx, prof in enumerate(chosen, start=1):
        with st.spinner(f"ğŸ”„ ××¨×™×¥ ×©××œ×•×Ÿ {idx}/{n} â€“ Geminiâ€¦"):
            status_box.info(f"â³ ×¡×˜×˜×•×¡: ×©××œ×•×Ÿ {idx}/{n} â€¢ ×›×œ×™: Gemini â€¢ QID={prof['profile_id']}")
            gem_json = run_gemini(prof)

        with st.spinner(f"ğŸ”„ ××¨×™×¥ ×©××œ×•×Ÿ {idx}/{n} â€“ ChatGPTâ€¦"):
            status_box.info(f"â³ ×¡×˜×˜×•×¡: ×©××œ×•×Ÿ {idx}/{n} â€¢ ×›×œ×™: ChatGPT â€¢ QID={prof['profile_id']}")
            gpt_pack = run_chat_gpt(prof)

        with st.spinner(f"ğŸ” ××¢×¨×™×š ×ª×•×¦××•×ª ×œ×©××œ×•×Ÿ {idx}/{n}â€¦"):
            status_box.info(f"â³ ×¡×˜×˜×•×¡: ×”×¢×¨×›×” â€¢ QID={prof['profile_id']}")
            eval_obj = run_evaluator(prof, gem_json, gpt_pack)

        row = {
            "ts": datetime.now().isoformat(),
            "profile": prof,
            "gemini_json": gem_json,       # ×›×œ ××” ×©×’×™××™× ×™ ×›×ª×‘ â€“ × ×›× ×¡ ×™×©×¨ ×œ×˜×‘×œ×” (JSON ××œ×)
            "gpt_raw": gpt_pack.get("_raw",""),   # ××” ×©×¦'××˜ ×›×ª×‘ â€“ ×˜×§×¡×˜ ×’×•×œ××™
            "gpt_json": gpt_pack.get("_json",{}), # ×•×× ×”×™×” JSON â€“ × ×›× ×™×¡ ×’× ××•×ª×•
            "eval": eval_obj
        }
        run_rows.append(row)
        append_row(RUN_ROWS_FILE, row)

        progress.progress(idx / n)

    # ×¡×™×›×•× ×¨×™×¦×”
    summary = {
        "ts": datetime.now().isoformat(),
        "n": n,
        "winners_count": {
            "Gemini": sum(1 for r in run_rows if r.get("eval",{}).get("winner") == "Gemini"),
            "ChatGPT": sum(1 for r in run_rows if r.get("eval",{}).get("winner") == "ChatGPT"),
            "Tie": sum(1 for r in run_rows if r.get("eval",{}).get("winner") == "Tie"),
        },
        "avg_scores": {
            "gemini": round(sum(r.get("eval",{}).get("gemini_score",0) for r in run_rows)/len(run_rows), 2),
            "gpt": round(sum(r.get("eval",{}).get("gpt_score",0) for r in run_rows)/len(run_rows), 2),
        }
    }
    append_row(RUN_SUMMARY_FILE, summary)
    status_box.success("âœ… ×”×¨×¦×” ×”×•×©×œ××”. ×”×˜×‘×œ×” ×”××œ××” ××•×›× ×” ×œ××˜×”.")

# ==========================
# TABLE RENDER (××•×’××¨)
# ==========================
st.divider()
st.subheader("ğŸ“Š ×˜×‘×œ×ª ×¤×œ×˜ â€“ ×›×œ ×”××™×“×¢ ×•×”×¦×™×•× ×™×")

def flatten_for_table(r: Dict[str, Any]) -> Dict[str, Any]:
    prof = r.get("profile", {})
    gem = r.get("gemini_json", {})
    gpt_raw = (r.get("gpt_raw") or "").strip()
    gpt_j = r.get("gpt_json", {})
    ev = r.get("eval", {})

    # ××§×‘×¥ ×ª××¦×™×ª ×”××œ×¦×•×ª (×× ×§×™×™××•×ª)
    def recs_from_gem(x):
        out = []
        for it in (x.get("recommendations") or []):
            car = it.get("car","")
            why = it.get("why","")
            out.append(f"{car} â€“ {why}")
        return " | ".join(out) if out else ""

    def recs_from_gpt_json(x):
        # × ×¡×” ×œ×§×¨×•× ××‘× ×” × ×¤×•×¥: ×¨×©×™××ª ×¨×›×‘×™× ×¢× "why"
        if not x:
            return ""
        candidates = []
        # ×—×¤×© ××¤×ª×—×•×ª ××¤×©×¨×™×™×
        if isinstance(x, dict):
            for k, v in x.items():
                if isinstance(v, list):
                    for it in v:
                        if isinstance(it, dict):
                            car = it.get("car") or it.get("name") or it.get("model") or ""
                            why = it.get("why") or it.get("reason") or ""
                            if car or why:
                                candidates.append(f"{car} â€“ {why}".strip(" â€“"))
        return " | ".join(candidates)

    return {
        "time": r.get("ts","")[:19].replace("T"," "),
        "QID": prof.get("profile_id",""),
        # ×ª×§×¦×™×¨ ×©××œ×•×Ÿ
        "×ª×§×¦×™×‘": prof.get("budget_nis",""),
        "×©×™××•×© ×¢×™×§×¨×™": prof.get("primary_use",""),
        "×¢×“×™×¤×•×ª ×¨××©×™×ª": prof.get("preferences",{}).get("priority_primary",""),
        "×“×œ×§": prof.get("preferences",{}).get("engine_type",""),
        "×ª×™×‘×”": prof.get("preferences",{}).get("gearbox",""),
        "××©×¤×—×”": prof.get("family_size",""),
        # ×¤×œ×˜ Gemini (×›×œ ×”-JSON × ×©××¨ ×‘×§×•×‘×¥; ×‘×˜×‘×œ×” â€“ ×ª××¦×™×ª ×§×¨×™××”)
        "Gemini: ×¦×™×•×Ÿ": gem.get("deal_score",""),
        "Gemini: ×¡×™×•×•×’": gem.get("classification",""),
        "Gemini: ×¤×¡×§×”": gem.get("short_verdict",""),
        "Gemini: ×”××œ×¦×•×ª": recs_from_gem(gem),
        # ×¤×œ×˜ GPT
        "GPT: ×˜×§×¡×˜ ×’×•×œ××™": gpt_raw[:500] + ("..." if len(gpt_raw) > 500 else ""),
        "GPT: ×”××œ×¦×•×ª (×× JSON)": recs_from_gpt_json(gpt_j),
        # ×”×¢×¨×›×”
        "Evaluator: Gemini score": ev.get("gemini_score",""),
        "Evaluator: GPT score": ev.get("gpt_score",""),
        "Evaluator: Winner": ev.get("winner",""),
        "Evaluator: Reason": ev.get("reason",""),
    }

# ×‘× ×” ×˜×‘×œ×ª ×¨×™×¦×” ××—×¨×•× ×” ×× ×™×©, ××—×¨×ª ××”×§×•×‘×¥
display_rows = run_rows if run_rows else prev_rows
if display_rows:
    table = pd.DataFrame([flatten_for_table(r) for r in display_rows])
    st.dataframe(table, use_container_width=True)
    # ×™×¦×•×
    csv_bytes = table.to_csv(index=False).encode("utf-8-sig")
    st.download_button("â¬‡ï¸ ×”×•×¨×“ CSV ×©×œ ×”×ª×•×¦××•×ª", csv_bytes, file_name="car_advisor_ab_results.csv", mime="text/csv")
else:
    st.info("××™×Ÿ × ×ª×•× ×™× ×œ×”×¦×’×” ×¢×“×™×™×Ÿ. ×œ×—×¥ ×¢×œ '×”×ª×—×œ ×”×¨×¦×” ×¨×¦×™×¤×”'.")


st.caption("Â© 2025 Car Advisor â€“ A/B Reliability Harness. ×›×•×œ×œ ×¡×¤×™× ×¨ ×¡×˜×˜×•×¡, Retry ×œ×›×©×œ×™×, ×•×©××™×¨×” ×œ×•×§××œ×™×ª ×©×œ ×›×œ ×”×¤×œ×˜×™×.")
